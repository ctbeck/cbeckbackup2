---
title: "Assignment8_Beck"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = F, message = F)
```

```{r}
library(censusapi)
library(tidyverse)
library(tidycensus)
library(tigris)
library(sf)
library(leaflet)
library(StatMatch)


Sys.setenv(CENSUS_KEY="c18a7f6e5cbbd1e7f0d3047d8b674cbaad89bcb3")
```



```{r}
ca_pumas <-
  pumas("CA", cb = T, progress_bar = F)

bay_county_names <-
  c(
    "Alameda",
    "Contra Costa",
    "Marin",
    "Napa",
    "San Francisco",
    "San Mateo",
    "Santa Clara",
    "Solano",
    "Sonoma"
  )

bay_counties <-
  counties("CA", cb = T, progress_bar = F) %>%
  filter(NAME %in% bay_county_names)

bay_pumas <-
  ca_pumas %>% 
  st_centroid() %>% 
  .[bay_counties, ] %>% 
  st_drop_geometry() %>% 
  left_join(ca_pumas %>% select(GEOID10)) %>% 
  st_as_sf()

leaflet() %>% 
  addProviderTiles(providers$CartoDB.Positron) %>% 
  addPolygons(
    data = bay_pumas,
    weight = 1,
    color = "gray",
    label = ~PUMACE10
  ) %>% 
  addMarkers(
    lng = -121.8162, ##directly add long and lat. 
    lat = 38.0178
  ) %>% 
  addPolygons(
    data = bay_pumas %>% 
      filter(PUMACE10 == "01309")
  )
```

```{r}
pums_2014_2019 <- readRDS("pums_2014_2019_wts.rds")

pums_bart <- pums_2014_2019 %>%
  mutate(
    PWGTP = as.numeric(PWGTP),
    bart = ifelse(
      JWTR %in% c("4"),
      PWGTP,
      0
    )
  ) %>% 
  group_by(PUMA, year) %>% 
  summarize(
    pop = sum(PWGTP),
    bart = sum(bart)
  )
```

Map distribution of population and BART commuters in the Bay Area PUMAs

```{r}
pums_pal <- colorNumeric(
  palette = "YlOrRd",
  domain = pums_bart %>% 
    filter(year == 2018) %>% 
    pull(pop)
)

leaflet() %>% 
  addProviderTiles(providers$CartoDB.Positron) %>% 
  addPolygons(
    data = pums_bart %>% 
      filter(year == 2018) %>% 
      right_join(bay_pumas %>% select(PUMA = PUMACE10)) %>% 
      st_as_sf(),
    fillColor = ~pums_pal(pop),
    color = "white",
    weight = 1,
    fillOpacity = 0.5,
    label = ~paste0(PUMA,": Population ", pop)
  )
```

Livermore and Pleasonton have a lot of people in it, but the PUMA is also very very big compared to the SF PUMA. This raw count is very misleading because of that. Oakland and Emeryville have high users based on its acerage. 


Map Bart Users
```{r}
pums_pal <- colorNumeric(
  palette = "GnBu",
  domain = pums_bart %>% 
    filter(year == 2018) %>% 
    pull(bart)
)

leaflet() %>% 
  addProviderTiles(providers$CartoDB.Positron) %>% 
  addPolygons(
    data = pums_bart %>% 
      filter(year == 2018) %>% 
      right_join(bay_pumas %>% select(PUMA = PUMACE10)) %>% 
      st_as_sf(),
    fillColor = ~pums_pal(bart),
    color = "white",
    weight = 1,
    fillOpacity = 0.5,
    label = ~paste0(PUMA,": ", bart, " BART commute riders")
  )
```

Some of the small PUMAs in Berkely, SF, and Oakland seem to have a lot of BART riders. But again this could be skewed becuase of its size. Ie, Livermore has a sparse number of BART riders in the area but it also has a very high acerage. 


Clean Data by removing pop data

```{r}
pums_bart_clean <-
  pums_bart %>% 
  select(-pop) %>% 
  pivot_wider( 
    names_from = year,
    values_from = bart
  )
```
Matching Technique

```{r}
obs_matrix <-
  pums_bart_clean %>% 
  ungroup() %>% 
  select(`2014`,`2015`,`2016`, `2017`) %>% 
  as.matrix()

dist_matrix <- mahalanobis.dist(obs_matrix)

rownames(dist_matrix) <- pums_bart_clean$PUMA
colnames(dist_matrix) <- pums_bart_clean$PUMA

match <- dist_matrix["01309",] %>% 
  as.data.frame() %>% 
  rownames_to_column() %>% 
  rename(
    PUMA = rowname,
    match = "."
  ) %>% 
  right_join(
    pums_bart_clean
  ) %>% 
  arrange(match) %>% 
  .[1:11, ] %>% 
  left_join(bay_pumas %>% select(PUMA = PUMACE10)) %>% 
  st_as_sf()
```
Map the Matrix Data

```{r}
leaflet() %>% 
  addTiles() %>% 
  addProviderTiles(providers$CartoDB.Positron) %>% 
  addPolygons(
    data = match[1, ],
    color = "red",
    label = ~PUMA
  ) %>% 
  addPolygons(
    data = match[-1, ],
    label = ~PUMA
  )
```

Difference in Differnece Treatment

```{r}
match_pumas <-
  match %>% 
  filter(!PUMA %in% c("01309")) %>% 
  st_drop_geometry() %>% 
  select(-match) %>% 
  pivot_longer(
    -PUMA,
    names_to = "year",
    values_to = "bart"
  ) %>%
  group_by(
    year
  ) %>% 
  summarize(
    bart = mean(bart),
    PUMA = "Similar PUMAs"
  )

treatment_pumas <-
  match %>% 
  filter(PUMA %in% c("01309")) %>% 
  select(-match) %>% 
  st_drop_geometry() %>% 
  pivot_longer(
    -PUMA,
    names_to = "year",
    values_to = "bart"
  )

rbind(
  treatment_pumas,
  match_pumas
) %>% 
  ggplot(
    aes(
      x = as.numeric(year),
      y = bart,
      color = PUMA
    )
  ) +
  geom_line() +
  geom_vline(xintercept = 2018, linetype = "dashed") +
  labs(
    title = "Brentwood/Oakley vs. control neighborhoods, BART ridership",
    x = "Year",
    y = "BART commute riders"
  )
```

In the year 2018, and the Antioch Bart station was built in 2017, a large number of riders now say they are BART riders. This slope between 2017 and 2018 is very steep. The effect size of this treatment is far greater than Milpitas and it's BART station.

Based on just the graph, it may seem clear that the selected PUMA has an increase in BART ridership relative to the control PUMAs, but given the scale of that difference and the averaging of the behavior of the control PUMAs (keep in mind we’re artificially viewing one teal line when in fact there are ten with possibly wide variation), we should withhold judgment until we see the results of the formal difference-in-differences analysis.

Generate Diff in Diff Regression

```{r}
transit_did <-
  match %>% 
  st_drop_geometry() %>% 
  select(-match) %>% 
  pivot_longer(
    -PUMA,
    names_to = "year",
    values_to = "bart"
  ) %>% 
  mutate(
    year = year %>% as.numeric(),
    time = ifelse(year >= 2018, 1, 0),
    treated = ifelse(PUMA == "01309", 1, 0)
  )

did_reg <- lm(bart ~ treated*time, data = transit_did)

summary(did_reg)
```
Commentary: 
Treated = 470 compared to 157 from the textbook 
Time = 207, the baseline change is quite high, just like in the textbook
DiD: 1097.22 is the difference in difference which again is way higher than the textbook. The unique contribution of the BART station has really affected this PUMA. 
This result was significant with a p-value of 0.001 compared to the textbook example. 

The “difference-in-differences” result of interest, is that the Antioch BART station in 2018, as having had an estimated impact of about 1097 new BART commuters. Unlike the textbook example, the positive effect size of the treatment and the previous plot are statistically significant (i.e. p-value is less than 5%), so we can come to some conlcusion with this analysis. Being that, the result of the BART station increased the ridership. 

<br>

Model Assumptions:

1. We chose a particular outcome to evaluate, bart, which may not be the most pronounced or important possible causal effect of a BART station to evaluate. Perhaps the key ridership is arriving at the Antioch station, not leaving from it (which would not be observable using the same kind of PUMS analysis). Perhaps the greater impact of a station is on commercial and residential development. Perhaps ridership has increased, but just not as the travel mode for work trips. That being said, commute ridership would seem to be a very straightforward measure of the impact of a BART station in a community.

2. We are assuming that respondents picked “Subway or elevated car” in the ACS questionnaire to represent a BART commute trip.

3. We did not have the cleanest geographies to choose from, so the particular PUMA we chose to consider as “treated” may have been too big to see the relevant effect, which may have been mainly on neighborhoods within biking/walking distance of the station. On the other hand, we may not have picked enough PUMAs, if most riders are driving in from further away.

4. We did not match based on any other variables other than 2014-2016 train ridership. For example, we could have “controlled for” other variables like employment, income, demographics, in the same way we would have done a multiple regression.

5. We are using PUMS data which may introduce greater noise because of lower sample size relative to other possible datasets. In this example we did not incorporate replicate weights for simplicity; if you were to include them, you’d get a lower standard error on treated:time, making this result almost statistically significant.

